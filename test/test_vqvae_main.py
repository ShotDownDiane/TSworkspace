#!/usr/bin/env python3
"""
VQ-VAE æµ‹è¯•è„šæœ¬
æµ‹è¯• VQ-VAE æ¨¡å‹çš„å„ä¸ªåŠŸèƒ½ï¼šç¼–ç ã€è§£ç ã€é‡åŒ–ã€è®­ç»ƒç­‰
"""

import torch
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from tsflow.module.vqvae import VQVAE


def create_test_config():
    """åˆ›å»ºæµ‹è¯•ç”¨çš„ VQ-VAE é…ç½®"""
    return {
        'block_hidden_size': 128,      # éšè—å±‚å¤§å°
        'num_residual_layers': 2,      # æ®‹å·®å±‚æ•°é‡
        'res_hidden_size': 32,         # æ®‹å·®å±‚éšè—å¤§å°
        'embedding_dim': 64,           # åµŒå…¥ç»´åº¦
        'num_embeddings': 512,         # ç æœ¬å¤§å°
        'commitment_cost': 0.25,       # æ‰¿è¯ºæŸå¤±æƒé‡
        'compression_factor': 4        # å‹ç¼©ç‡ (4, 8, 12, 16)
    }


def generate_test_data(batch_size=8, seq_length=256):
    """ç”Ÿæˆæµ‹è¯•ç”¨çš„æ—¶é—´åºåˆ—æ•°æ®"""
    # ç”Ÿæˆå¤šç§ç±»å‹çš„æ—¶é—´åºåˆ—
    t = torch.linspace(0, 4*np.pi, seq_length)
    
    # æ­£å¼¦æ³¢ + å™ªå£°
    sine_waves = torch.sin(t.unsqueeze(0) * torch.randn(batch_size//2, 1) * 2) + 0.1 * torch.randn(batch_size//2, seq_length)
    
    # ä½™å¼¦æ³¢ + è¶‹åŠ¿
    cos_waves = torch.cos(t.unsqueeze(0) * torch.randn(batch_size//2, 1) * 1.5) + t.unsqueeze(0) * 0.1 + 0.1 * torch.randn(batch_size//2, seq_length)
    
    # åˆå¹¶æ•°æ®
    data = torch.cat([sine_waves, cos_waves], dim=0)
    
    # æ ‡å‡†åŒ–
    data = (data - data.mean(dim=1, keepdim=True)) / (data.std(dim=1, keepdim=True) + 1e-8)
    
    return data


def test_model_initialization():
    """æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–"""
    print("=" * 50)
    print("æµ‹è¯• 1: æ¨¡å‹åˆå§‹åŒ–")
    print("=" * 50)
    
    config = create_test_config()
    model = VQVAE(config)
    
    print(f"âœ“ æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
    print(f"  - å‹ç¼©ç‡: {model.compression_factor}")
    print(f"  - åµŒå…¥ç»´åº¦: {config['embedding_dim']}")
    print(f"  - ç æœ¬å¤§å°: {config['num_embeddings']}")
    
    # æ‰“å°æ¨¡å‹å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"  - æ€»å‚æ•°æ•°: {total_params:,}")
    print(f"  - å¯è®­ç»ƒå‚æ•°æ•°: {trainable_params:,}")
    
    return model


def test_forward_pass(model):
    """æµ‹è¯•å‰å‘ä¼ æ’­"""
    print("\n" + "=" * 50)
    print("æµ‹è¯• 2: å‰å‘ä¼ æ’­")
    print("=" * 50)
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    batch_size, seq_length = 4, 256
    test_data = generate_test_data(batch_size, seq_length)
    
    print(f"è¾“å…¥æ•°æ®å½¢çŠ¶: {test_data.shape}")
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        recon, vq_loss, quantized, perplexity, embedding_weight, encoding_indices, encodings = model(test_data)
    
    print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
    print(f"  - é‡æ„æ•°æ®å½¢çŠ¶: {recon.shape}")
    print(f"  - é‡åŒ–æŸå¤±: {vq_loss.item():.4f}")
    print(f"  - å›°æƒ‘åº¦: {perplexity.item():.4f}")
    print(f"  - ç¼–ç ç´¢å¼•å½¢çŠ¶: {encoding_indices.shape}")
    print(f"  - é‡åŒ–åå½¢çŠ¶: {quantized.shape}")
    
    # è®¡ç®—é‡æ„è¯¯å·®
    recon_error = F.mse_loss(recon, test_data)
    print(f"  - é‡æ„è¯¯å·® (MSE): {recon_error.item():.4f}")
    
    return test_data, recon, encoding_indices


def test_encode_decode(model):
    """æµ‹è¯•ç¼–ç å’Œè§£ç åŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("æµ‹è¯• 3: ç¼–ç /è§£ç åŠŸèƒ½")
    print("=" * 50)
    
    test_data = generate_test_data(2, 128)
    print(f"è¾“å…¥æ•°æ®å½¢çŠ¶: {test_data.shape}")
    
    # æµ‹è¯•ç¼–ç 
    with torch.no_grad():
        encoded = model.encode(test_data)
        print(f"âœ“ ç¼–ç æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {encoded.shape}")
        
        # æµ‹è¯•è§£ç 
        decoded = model.decode(encoded)
        print(f"âœ“ è§£ç æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {decoded.shape}")
        
        # éªŒè¯å½¢çŠ¶ä¸€è‡´æ€§
        assert test_data.shape == decoded.shape, f"å½¢çŠ¶ä¸åŒ¹é…: {test_data.shape} vs {decoded.shape}"
        print(f"âœ“ è¾“å…¥è¾“å‡ºå½¢çŠ¶ä¸€è‡´")


def test_different_compression_factors():
    """æµ‹è¯•ä¸åŒå‹ç¼©ç‡"""
    print("\n" + "=" * 50)
    print("æµ‹è¯• 4: ä¸åŒå‹ç¼©ç‡")
    print("=" * 50)
    
    compression_factors = [4, 8, 12, 16]
    test_data = generate_test_data(2, 256)
    
    for cf in compression_factors:
        print(f"\næµ‹è¯•å‹ç¼©ç‡ {cf}x:")
        config = create_test_config()
        config['compression_factor'] = cf
        
        try:
            model = VQVAE(config)
            with torch.no_grad():
                encoded = model.encode(test_data)
                decoded = model.decode(encoded)
                
            expected_length = test_data.shape[-1] // cf
            actual_length = encoded.shape[-1]
            
            print(f"  âœ“ å‹ç¼©ç‡ {cf}x æµ‹è¯•æˆåŠŸ")
            print(f"    - åŸå§‹é•¿åº¦: {test_data.shape[-1]}")
            print(f"    - ç¼–ç é•¿åº¦: {actual_length} (æœŸæœ›: {expected_length})")
            print(f"    - è§£ç å½¢çŠ¶: {decoded.shape}")
            
        except Exception as e:
            print(f"  âœ— å‹ç¼©ç‡ {cf}x æµ‹è¯•å¤±è´¥: {e}")


def test_training_step(model):
    """Test training steps with more iterations to see improvement"""
    print("\n" + "=" * 50)
    print("Test 5: Training Steps")
    print("=" * 50)
    
    # Create optimizer
    optimizer = model.configure_optimizers(lr=1e-3)
    
    # Generate training data
    train_data = generate_test_data(8, 256)
    
    print(f"Training data shape: {train_data.shape}")
    
    # Train for more steps to see improvement
    losses = []
    recon_errors = []
    perplexities = []
    
    print("Training progress:")
    for step in range(50):  # More training steps
        # Use shared_eval method for training
        loss, vq_loss, recon_error, data_recon, perplexity, _, _, _ = model.shared_eval(
            train_data, optimizer, mode='train'
        )
        
        losses.append(loss.item())
        recon_errors.append(recon_error.item())
        perplexities.append(perplexity.item())
        
        if step % 10 == 0:  # Print every 10 steps
            print(f"  Step {step+1:2d}: Loss={loss.item():.4f}, Recon={recon_error.item():.4f}, Perplexity={perplexity.item():.2f}")
    
    print(f"\nâœ“ Completed 50 training steps")
    print(f"  - Initial loss: {losses[0]:.4f}")
    print(f"  - Final loss: {losses[-1]:.4f}")
    print(f"  - Loss improvement: {losses[0] - losses[-1]:.4f}")
    print(f"  - Initial recon error: {recon_errors[0]:.4f}")
    print(f"  - Final recon error: {recon_errors[-1]:.4f}")
    print(f"  - Recon improvement: {recon_errors[0] - recon_errors[-1]:.4f}")
    
    return train_data, data_recon


def test_evaluation_mode(model):
    """æµ‹è¯•è¯„ä¼°æ¨¡å¼"""
    print("\n" + "=" * 50)
    print("æµ‹è¯• 6: è¯„ä¼°æ¨¡å¼")
    print("=" * 50)
    
    test_data = generate_test_data(4, 256)
    
    # æµ‹è¯•éªŒè¯æ¨¡å¼
    loss, vq_loss, recon_error, data_recon, perplexity, _, _, _ = model.shared_eval(
        test_data, optimizer=None, mode='val'
    )
    
    print(f"âœ“ éªŒè¯æ¨¡å¼æµ‹è¯•æˆåŠŸ")
    print(f"  - æ€»æŸå¤±: {loss.item():.4f}")
    print(f"  - VQæŸå¤±: {vq_loss.item():.4f}")
    print(f"  - é‡æ„è¯¯å·®: {recon_error.item():.4f}")
    print(f"  - å›°æƒ‘åº¦: {perplexity.item():.4f}")
    
    # æµ‹è¯•æµ‹è¯•æ¨¡å¼
    loss, vq_loss, recon_error, data_recon, perplexity, _, _, _ = model.shared_eval(
        test_data, optimizer=None, mode='test'
    )
    
    print(f"âœ“ æµ‹è¯•æ¨¡å¼æµ‹è¯•æˆåŠŸ")
    print(f"  - æ€»æŸå¤±: {loss.item():.4f}")


def visualize_reconstruction(original, reconstructed, encoding_indices, save_path=None, title_suffix=""):
    """Visualize reconstruction results"""
    print("\n" + "=" * 50)
    print("Test 7: Visualization of Reconstruction Results")
    print("=" * 50)
    
    # Select first two samples for visualization
    fig, axes = plt.subplots(2, 3, figsize=(15, 8))
    
    for i in range(2):
        # Original vs Reconstructed signals
        axes[i, 0].plot(original[i].numpy(), label='Original', color='blue', linewidth=2)
        axes[i, 0].plot(reconstructed[i].detach().numpy(), label='Reconstructed', color='red', alpha=0.8, linewidth=2)
        axes[i, 0].set_title(f'Sample {i+1}: Original vs Reconstructed{title_suffix}')
        axes[i, 0].legend()
        axes[i, 0].grid(True, alpha=0.3)
        
        # Encoding indices
        axes[i, 1].plot(encoding_indices[i].numpy(), marker='o', markersize=3, linewidth=1)
        axes[i, 1].set_title(f'Sample {i+1}: Encoding Indices')
        axes[i, 1].set_ylabel('Codebook Index')
        axes[i, 1].grid(True, alpha=0.3)
        
        # Reconstruction error over time
        error = (original[i] - reconstructed[i].detach()).numpy()
        axes[i, 2].plot(error, color='green', linewidth=1)
        axes[i, 2].set_title(f'Sample {i+1}: Reconstruction Error')
        axes[i, 2].set_ylabel('Error')
        axes[i, 2].grid(True, alpha=0.3)
        
        # Calculate and display metrics
        mse = np.mean(error**2)
        mae = np.mean(np.abs(error))
        axes[i, 2].text(0.02, 0.98, f'MSE: {mse:.4f}\nMAE: {mae:.4f}', 
                       transform=axes[i, 2].transAxes, verticalalignment='top',
                       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"âœ“ Visualization saved to: {save_path}")
    else:
        plt.show()
        print(f"âœ“ Visualization completed")
    
    plt.close()


def run_comprehensive_test():
    """Run comprehensive VQ-VAE tests"""
    print("ğŸš€ Starting Comprehensive VQ-VAE Tests")
    print("=" * 60)
    
    try:
        # 1. Model initialization test
        model = test_model_initialization()
        
        # 2. Forward pass test (before training)
        print("\n" + "=" * 50)
        print("BEFORE TRAINING:")
        print("=" * 50)
        original, reconstructed, encoding_indices = test_forward_pass(model)
        
        # Visualize before training
        visualize_reconstruction(original, reconstructed, encoding_indices, 
                               save_path='../vqvae_before_training.png', 
                               title_suffix=" (Before Training)")
        
        # 3. Encode/decode test
        test_encode_decode(model)
        
        # 4. Different compression factors test
        test_different_compression_factors()
        
        # 5. Training step test
        train_data, trained_recon = test_training_step(model)
        
        # Test forward pass after training
        print("\n" + "=" * 50)
        print("AFTER TRAINING:")
        print("=" * 50)
        with torch.no_grad():
            recon_after, vq_loss_after, quantized_after, perplexity_after, _, encoding_indices_after, _ = model(train_data[:2])
        
        print(f"âœ“ Forward pass after training")
        print(f"  - VQ loss after training: {vq_loss_after.item():.4f}")
        print(f"  - Perplexity after training: {perplexity_after.item():.4f}")
        
        # Visualize after training
        visualize_reconstruction(train_data[:2], recon_after, encoding_indices_after, 
                               save_path='../vqvae_after_training.png',
                               title_suffix=" (After Training)")
        
        # 6. Evaluation mode test
        test_evaluation_mode(model)
        
        print("\n" + "=" * 60)
        print("ğŸ‰ All tests completed! Check the generated images to see improvement:")
        print("   - ../vqvae_before_training.png: Reconstruction before training")
        print("   - ../vqvae_after_training.png: Reconstruction after training")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ Error during testing: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯é‡ç°
    torch.manual_seed(42)
    np.random.seed(42)
    
    # è¿è¡Œæµ‹è¯•
    run_comprehensive_test()